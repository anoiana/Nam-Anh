{
  "articles": [
    {
      "path": "010101.html",
      "title": "Bayesian Computational Approaches",
      "author": [
        {
          "name": "Nam Anh",
          "url": {}
        }
      ],
      "date": "Oct. 11, 2021",
      "contents": "\n\nContents\nMaximize posterior distribution\nNumerical integration\nMarkov Chain Monte Carlo (MCMC)\n\nMaximize posterior distribution\nLet us define \\(p(\\boldsymbol{\\theta}|\\boldsymbol{Y})\\) be posterior distribution, and\n\\[\n\\widehat{\\boldsymbol{\\theta}}_{MAP} = \\arg\\max_{\\boldsymbol{\\theta}}\\ln p(\\boldsymbol{\\theta}|\\boldsymbol{Y}) = \\arg\\max_{\\boldsymbol{\\theta}}\\ln f(\\boldsymbol{Y}|\\boldsymbol{\\theta}) + \\ln \\pi(\\boldsymbol{\\theta})\n\\tag{1}\n\\] is the maximizer of \\(p(\\boldsymbol{\\theta}|\\boldsymbol{Y})\\).\nMAP estimator can be obtained by function optim in R. Its illustration in R will be pored over latter.\nNumerical integration\nSome summary statistics of interest can be written as integrals, so they can be approximated by summations. For example, expectation, variance and proportions of a distribution can be written as follows\n\\[\n\\begin{aligned}\n\\Bbb{E}(\\theta|\\boldsymbol{Y}) &= \\int \\theta_1p(\\theta|\\boldsymbol{Y})d\\theta \\\\\n\\Bbb{V}(\\theta|\\boldsymbol{Y}) &= \\int [\\theta - \\Bbb{E}(\\theta|\\boldsymbol{Y})]^2p(\\theta|\\boldsymbol{Y})d\\theta \\\\\n\\Bbb{P}(\\theta > c|\\boldsymbol{Y}) &= \\int_c^{\\infty}p(\\theta|\\boldsymbol{Y})d\\theta\n\\end{aligned}\n\\tag{2}\n\\]\nAll three measures in (2) can be rewritten as \\(\\Bbb{E}[g(\\theta)]\\), for example, \\(\\Bbb{P}(\\theta > c| \\boldsymbol{Y})\\) is equivalent to\n\\[\n\\int_{-\\infty}^{\\infty}{\\large\\unicode{x1D7D9}}_{\\theta > c}(\\theta)p(\\theta|\\boldsymbol{Y})d\\theta\n\\]\nSince integration can be approximated by summation, \\(\\Bbb{E}[g(\\theta)] = \\int_{\\Theta}g(\\theta)p(\\theta|\\boldsymbol{Y})\\) is equivalent to\n\\[\n\\sum_{j=1}^m g(\\theta_j)W_j,\n\\]\nwhere \\(W_j\\) is the weight given to the grid point \\(j\\).\nMarkov Chain Monte Carlo (MCMC)\nMonte Carlo (MC) methods are appealing since they mimic the process of statistical concept where a sample is used to draw inferences of population. Two well-known measures are first two moments of distribution, i.e. \\(\\Bbb{E}(X)\\) and \\(\\Bbb{E}(X^2)\\).\n\n\n\n",
      "last_modified": "2021-11-23T22:37:29-05:00"
    },
    {
      "path": "010201.html",
      "title": "Bayesian Meta Analysis",
      "author": [
        {
          "name": "Nam Anh",
          "url": {}
        }
      ],
      "date": "Nov. 20, 2021",
      "contents": "\n\nContents\nIntroduction to 2 arm analysis\nMeta analysis of binomial data\nForward to indirect network meta-analysis\nMulti-arm trials\nExample\n\n\nIntroduction to 2 arm analysis\nWe shall consider a set of M studies in which each study is denoted by \\(i \\in \\{1,\\dots,M\\}\\) and has 2 treatment arms, say \\(k \\in \\{1,2\\}\\). A fixed effects analysis assumes study \\(i\\) generates the same parameter \\(d_{12}\\), a relative effect of treatment \\(2\\) and \\(1\\). The relative effect is denoted \\(\\delta_{i,12}\\) in random effect analysis and specific to study \\(i\\). This means \\(\\delta_{i,12}\\) is a trial-specific effect of treatment \\(2\\) and \\(1\\) in study \\(i\\). In Bayesian framework, \\(\\delta_{i,12}\\) is distributed normally as follows\n\\[\n\\delta_{i,12} \\sim \\mathcal{N}(d_{12},\\sigma^2_{12}),\n\\]\nin fixed effects analysis, \\(\\sigma^2_{12} = 0\\) that means \\(\\delta_{i,12} = d_{12}, \\forall i\\). Distribution of \\(d_{12}\\) is known as prior distribution, and the common distribution used such a prior distribution is normal, so\n\\[\nd_{12} \\sim \\mathcal{N}(0, 100^2)\n\\]\nDistribution of between-study variance \\(\\sigma^2_{12}\\) widely used is uniform whose lower bound is zero and upper bound is chosen suitably according to knowledge of researcher.\nMeta analysis of binomial data\nLet us consider 11 studies (\\(M=11\\)), each study compares 2 treatments, active and control arm. Let \\(r_{ik}\\) and \\(n_{ik}\\) be the number of event and sample size in arm \\(k\\) of trial \\(i\\), respectively. Thus,\n\\[\nr_{ik} \\sim \\mathcal{B} in(p_{ik},n_{ik}).\n\\]\nLink function used to model probability of events is logit, \\(logit(x) = x/(1-x)\\), so\n\\[\nlogit(p_{ik}) = \\mu_i + \\delta_{i,1k}.\n\\]\nRecall that \\(\\delta_{i,1k}\\) is relative effect of treatment \\(k\\) compared with treatment \\(1\\), so \\(\\delta_{i,11} = 0, \\forall i\\). \\(\\delta_{i1k}\\) is equal to \\(d_{1k}\\) in fixed effect analysis.\nPrior distributions chosen for parameters are\n\\[\n\\mu_i \\sim \\mathcal{N}(0,100^2); \\quad \\delta_{i,12} \\sim \\mathcal{N}(d_{12}, \\sigma^2_{12}),\n\\]\nand\n\\[\n\\sigma^2_{12} \\sim \\mathcal{U}(0,2)\n\\]\n\n\nhide\n\nlibrary(rjags); library(tidyverse); library(magrittr)\nload(\"_data/thrombolytic.RData\")\n\ndata = purrr::splice(d, \"ns\" = nrow(d$r))\n\nmodel_string <- textConnection(\n\"model{ # *** PROGRAM STARTS\nfor(i in 1:ns){ # LOOP THROUGH STUDIES\nmu[i] ~ dnorm(0,.0001) # vague priors for all trial baselines\nfor (k in 1:2) { # LOOP THROUGH ARMS\nr[i,k] ~ dbin(p[i,k],n[i,k]) # binomial likelihood\nlogit(p[i,k]) <- mu[i] + d[k] # model for linear predictor\n}\n}\nd[1]<- 0 # treatment effect is zero for reference treatment\nd[2] ~ dnorm(0,.0001) # vague prior for treatment effect\n}\"\n)\n# *** PROGRAM ENDS\n\ninits <- list(d=c( NA, -1), mu=c(-3,-3,-3,-3,-3, -3,-3,-3,-3,-3, -3))\nmodel <- jags.model(model_string,data = data, inits=inits, n.chains=2, quiet = T)\n\nupdate(model, 10000, progress.bar=\"none\")\n\nparameters <- c(\"d[2]\")\nsamples <- coda.samples(model,\n                           variable.names=parameters,\n                           n.iter=20000, progress.bar=\"none\")\n\ns = summary(samples)\n\n\n\nRunning MCMC using code above, we obtain summary statistics as follows\n\n\nhide\n\nlift_dv(tibble)(c(s[[1]][1:2], s[[2]]))%>%\n     knitr::kable()\n\n\nMean\nSD\n2.5%\n25%\n50%\n75%\n97.5%\n-0.2339332\n0.1177529\n-0.4643134\n-0.3133644\n-0.2342242\n-0.1549683\n-0.0037466\n\nForward to indirect network meta-analysis\nTwo arm studies were considered in previous section, we now extend the result by including studies with more than two arms. It means we will consider \\(\\delta_{i,1k}\\) with \\(k = 1,2,\\dots,S\\). It is worth noting that the transitivity relation is supposed to be true, which means\n\\[\n\\delta_{i,kk'} = \\delta_{i,1k'} - \\delta_{i,1k},\n\\]\nand that is called indirect treatment comparison (ITC). Its prior distribution is\n\\[\n\\delta_{i,kk'} \\sim \\mathcal{N}(d_{kk'}, \\sigma^2_{kk'}), \\quad k \\ne k'\n\\]\nIt can be shown that the above prior distribution impies\n\\[\nd_{kk'} = d_{1k'} - d_{1k}\n\\] and\n\\[\n\\sigma^2_{kk'} = \\sigma^2_{1k}+\\sigma^2_{1k'} - 2\\rho^{(1)}_{23}\\sigma_{12}\\sigma_{13}.\n\\]\nFor simplicity, we will assume that \\(\\sigma^2_{1k} = \\sigma^2_{1k'}\\) with \\(k \\ne k'\\) and \\(k,k' \\ge 2\\). This assumption is reasonable since we suppose population in all studies are the same, and trial designs are also similar across studies.\nTo allow comparison for multiple treatments, notations are revised such that arm \\(k\\) of trial \\(i\\) and treatments compared in that arm are distinguishable. The relative effect of the treatment in arm \\(k\\) and the treatment in arm \\(1\\) in trial \\(i\\) is \\(\\delta_{ik}\\) and it is distributed normally\n\\[\n\\delta_{ik} \\sim \\mathcal{N}(d_{t_{i1},t_{ik}}, \\sigma^2),\n\\]\nwhere \\(d_{t_{i1},t_{ik}}\\) is mean of relative effect between treatment in arm \\(k\\) and treatment in arm \\(1\\) of trial \\(i\\), and \\(\\delta_{i1} = 0, \\forall i\\). The general consistency equation is\n\\[\nd_{t_{i1},t_{ik}} = d_{1,t_{ik}} - d_{1,t_{ik}}\n\\]\n\\(d_{1k}\\) with \\(k=1,2,\\dots,S\\) are estimated, and to provide non-informative prior we assume\n\\[\nd_{1k} \\sim \\mathcal{N}(0, 100^2)\n\\]\nMulti-arm trials\nSuppose each study \\(i\\) has \\(a_i+1\\) treatments (1 reference, e.g. control or placebo, and \\(a_i\\) treatments), so all effect measures of treatment in arm \\(k\\) compared with treatment in arm \\(1\\) are \\(\\boldsymbol{\\delta}_i = (\\delta_{i,12}, \\delta_{i,13}, \\dots, \\delta_{i,1a_i})^{\\top}\\) and\n\\[\n\\boldsymbol{\\delta}_i = (\\delta_{i,12}, \\delta_{i,13}, \\dots, \\delta_{i,1a_i})^{\\top} \\sim \\mathcal{N}_{a_i}\\begin{pmatrix}\n\\begin{pmatrix}\nd_{t_{i1},t_{i2}}\\\\\nd_{t_{i1},t_{i3}}\\\\\n\\vdots\\\\\nd_{t_{i1},t_{ia_i}}\n\\end{pmatrix},\n\\begin{pmatrix}\n\\sigma^2 & \\sigma^2/2 & \\dots & \\sigma^2/2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma^2/2 & \\sigma^2/2 & \\dots & \\sigma^2\n\\end{pmatrix}\n\\end{pmatrix}\n\\] and we can show that\n\\[\n\\delta_{i,1k}|(\\delta_{i,12}, \\dots, \\delta_{i,1(k-1)})^{\\top} \\sim \\mathcal{N}\\Bigg(\n(d_{1,t_{ik}}-d_{1,t_{í}})+\\frac{1}{k-1}\\sum^{k-1}_{j=1}\\Big[\\delta_{i,1j}-\\big(d_{1,t_{ij}}-d_{1,t_{i1}}\\big)\\Big],\n\\frac{k}{2(k-1)}\\sigma^2\n\\Bigg)\n\\]\nExample\nWe shall consider the following example for illustration.\n\n\n\n",
      "last_modified": "2021-11-23T22:37:35-05:00"
    },
    {
      "path": "index.html",
      "title": "Bayesian Statistics",
      "description": "\"Begin with an estimate of the probability that any claim, belief, hypothesis is true, then look at any new data and update the probability given the new data.\"\n\n-Steven Novella-\n",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-11-23T22:37:36-05:00"
    }
  ],
  "collections": []
}
