{
  "articles": [
    {
      "path": "010101.html",
      "title": "Bayesian Computational Approaches",
      "author": [
        {
          "name": "Nam Anh",
          "url": {}
        }
      ],
      "date": "Oct. 11, 2021",
      "contents": "\n\nContents\nMaximize posterior distribution\nNumerical integration\nMarkov Chain Monte Carlo (MCMC)\n\nMaximize posterior distribution\nLet us define \\(p(\\boldsymbol{\\theta}|\\boldsymbol{Y})\\) be posterior distribution, and\n\\[\n\\widehat{\\boldsymbol{\\theta}}_{MAP} = \\arg\\max_{\\boldsymbol{\\theta}}\\ln p(\\boldsymbol{\\theta}|\\boldsymbol{Y}) = \\arg\\max_{\\boldsymbol{\\theta}}\\ln f(\\boldsymbol{Y}|\\boldsymbol{\\theta}) + \\ln \\pi(\\boldsymbol{\\theta})\n\\tag{1}\n\\] is the maximizer of \\(p(\\boldsymbol{\\theta}|\\boldsymbol{Y})\\).\nMAP estimator can be obtained by function optim in R. Its illustration in R will be pored over latter.\nNumerical integration\nSome summary statistics of interest can be written as integrals, so they can be approximated by summations. For example, expectation, variance and proportions of a distribution can be written as follows\n\\[\n\\begin{aligned}\n\\Bbb{E}(\\theta|\\boldsymbol{Y}) &= \\int \\theta_1p(\\theta|\\boldsymbol{Y})d\\theta \\\\\n\\Bbb{V}(\\theta|\\boldsymbol{Y}) &= \\int [\\theta - \\Bbb{E}(\\theta|\\boldsymbol{Y})]^2p(\\theta|\\boldsymbol{Y})d\\theta \\\\\n\\Bbb{P}(\\theta > c|\\boldsymbol{Y}) &= \\int_c^{\\infty}p(\\theta|\\boldsymbol{Y})d\\theta\n\\end{aligned}\n\\tag{2}\n\\]\nAll three measures in (2) can be rewritten as \\(\\Bbb{E}[g(\\theta)]\\), for example, \\(\\Bbb{P}(\\theta > c| \\boldsymbol{Y})\\) is equivalent to\n\\[\n\\int_{-\\infty}^{\\infty}{\\large\\unicode{x1D7D9}}_{\\theta > c}(\\theta)p(\\theta|\\boldsymbol{Y})d\\theta\n\\]\nSince integration can be approximated by summation, \\(\\Bbb{E}[g(\\theta)] = \\int_{\\Theta}g(\\theta)p(\\theta|\\boldsymbol{Y})\\) is equivalent to\n\\[\n\\sum_{j=1}^m g(\\theta_j)W_j,\n\\]\nwhere \\(W_j\\) is the weight given to the grid point \\(j\\).\nMarkov Chain Monte Carlo (MCMC)\nMonte Carlo (MC) methods are appealing since they mimic the process of statistical concept where a sample is used to draw inferences of population. Two well-known measures are first two moments of distribution, i.e. \\(\\Bbb{E}(X)\\) and \\(\\Bbb{E}(X^2)\\).\n\n\n\n",
      "last_modified": "2021-12-08T23:36:46-05:00"
    },
    {
      "path": "010201.html",
      "title": "Network Meta Analysis",
      "author": [
        {
          "name": "Nam Anh",
          "url": {}
        }
      ],
      "date": "Nov. 20, 2021",
      "contents": "\n\nContents\nIntroduction to 2 arm analysis\nMeta analysis of binomial data\nForward to indirect network meta-analysis\nMulti-arm trials\nExample\n\n\nIntroduction to 2 arm analysis\nWe shall consider a set of M studies in which each study is denoted by \\(i \\in \\{1,\\dots,M\\}\\) and has 2 treatment arms, say \\(k \\in \\{1,2\\}\\). A fixed effects analysis assumes study \\(i\\) generates the same parameter \\(d_{12}\\), a relative effect of treatment \\(2\\) and \\(1\\). The relative effect is denoted \\(\\delta_{i,12}\\) in random effect analysis and specific to study \\(i\\). This means \\(\\delta_{i,12}\\) is a trial-specific effect of treatment \\(2\\) and \\(1\\) in study \\(i\\). In Bayesian framework, \\(\\delta_{i,12}\\) is distributed normally as follows\n\\[\n\\delta_{i,12} \\sim \\mathcal{N}(d_{12},\\sigma^2_{12}),\n\\]\nin fixed effects analysis, \\(\\sigma^2_{12} = 0\\) that means \\(\\delta_{i,12} = d_{12}, \\forall i\\). Distribution of \\(d_{12}\\) is known as prior distribution, and the common distribution used such a prior distribution is normal, so\n\\[\nd_{12} \\sim \\mathcal{N}(0, 100^2)\n\\]\nDistribution of between-study variance \\(\\sigma^2_{12}\\) widely used is uniform whose lower bound is zero and upper bound is chosen suitably according to knowledge of researcher.\nMeta analysis of binomial data\nLet us consider 11 studies (\\(M=11\\)), each study compares 2 treatments, active and control arm. Let \\(r_{ik}\\) and \\(n_{ik}\\) be the number of event and sample size in arm \\(k\\) of trial \\(i\\), respectively. Thus,\n\\[\nr_{ik} \\sim \\mathcal{B} in(p_{ik},n_{ik}).\n\\]\nLink function used to model probability of events is logit, \\(logit(x) = x/(1-x)\\), so\n\\[\nlogit(p_{ik}) = \\mu_i + \\delta_{i,1k}.\n\\]\nRecall that \\(\\delta_{i,1k}\\) is relative effect of treatment \\(k\\) compared with treatment \\(1\\), so \\(\\delta_{i,11} = 0, \\forall i\\). \\(\\delta_{i1k}\\) is equal to \\(d_{1k}\\) in fixed effect analysis.\nPrior distributions chosen for parameters are\n\\[\n\\mu_i \\sim \\mathcal{N}(0,100^2); \\quad \\delta_{i,12} \\sim \\mathcal{N}(d_{12}, \\sigma^2_{12}),\n\\]\nand\n\\[\n\\sigma^2_{12} \\sim \\mathcal{U}(0,2)\n\\]\n\n\nhide\n\nlibrary(rjags); library(tidyverse); library(magrittr)\nload(\"_data/thrombolytic.RData\")\n\ndata = purrr::splice(d, \"ns\" = nrow(d$r))\n\nmodel_string <- textConnection(\n\"model{ # *** PROGRAM STARTS\nfor(i in 1:ns){ # LOOP THROUGH STUDIES\nmu[i] ~ dnorm(0,.0001) # vague priors for all trial baselines\nfor (k in 1:2) { # LOOP THROUGH ARMS\nr[i,k] ~ dbin(p[i,k],n[i,k]) # binomial likelihood\nlogit(p[i,k]) <- mu[i] + d[k] # model for linear predictor\n}\n}\nd[1]<- 0 # treatment effect is zero for reference treatment\nd[2] ~ dnorm(0,.0001) # vague prior for treatment effect\n}\"\n)\n# *** PROGRAM ENDS\n\ninits <- list(d=c( NA, -1), mu=c(-3,-3,-3,-3,-3, -3,-3,-3,-3,-3, -3))\nmodel <- jags.model(model_string,data = data, inits=inits, n.chains=2, quiet = T)\n\nupdate(model, 10000, progress.bar=\"none\")\n\nparameters <- c(\"d[2]\")\nsamples <- coda.samples(model,\n                           variable.names=parameters,\n                           n.iter=20000, progress.bar=\"none\")\n\ns = summary(samples)\n\n\n\nRunning MCMC using code above, we obtain summary statistics as follows\n\n\nhide\n\nlift_dv(tibble)(c(s[[1]][1:2], s[[2]]))%>%\n     knitr::kable()\n\n\n\nForward to indirect network meta-analysis\nTwo arm studies were considered in previous section, we now extend the result by including studies with more than two arms. It means we will consider \\(\\delta_{i,1k}\\) with \\(k = 1,2,\\dots,S\\). It is worth noting that the transitivity relation is supposed to be true, which means\n\\[\n\\delta_{i,kk'} = \\delta_{i,1k'} - \\delta_{i,1k},\n\\]\nand that is called indirect treatment comparison (ITC). Its prior distribution is\n\\[\n\\delta_{i,kk'} \\sim \\mathcal{N}(d_{kk'}, \\sigma^2_{kk'}), \\quad k \\ne k'\n\\]\nIt can be shown that the above prior distribution impies\n\\[\nd_{kk'} = d_{1k'} - d_{1k}\n\\] and\n\\[\n\\sigma^2_{kk'} = \\sigma^2_{1k}+\\sigma^2_{1k'} - 2\\rho^{(1)}_{23}\\sigma_{12}\\sigma_{13}.\n\\]\nFor simplicity, we will assume that \\(\\sigma^2_{1k} = \\sigma^2_{1k'}\\) with \\(k \\ne k'\\) and \\(k,k' \\ge 2\\). This assumption is reasonable since we suppose population in all studies are the same, and trial designs are also similar across studies.\nTo allow comparison for multiple treatments, notations are revised such that arm \\(k\\) of trial \\(i\\) and treatments compared in that arm are distinguishable. The relative effect of the treatment in arm \\(k\\) and the treatment in arm \\(1\\) in trial \\(i\\) is \\(\\delta_{ik}\\) and it is distributed normally\n\\[\n\\delta_{ik} \\sim \\mathcal{N}(d_{t_{i1},t_{ik}}, \\sigma^2),\n\\]\nwhere \\(d_{t_{i1},t_{ik}}\\) is mean of relative effect between treatment in arm \\(k\\) and treatment in arm \\(1\\) of trial \\(i\\), and \\(\\delta_{i1} = 0, \\forall i\\). The general consistency equation is\n\\[\nd_{t_{i1},t_{ik}} = d_{1,t_{ik}} - d_{1,t_{ik}}\n\\]\n\\(d_{1k}\\) with \\(k=1,2,\\dots,S\\) are estimated, and to provide non-informative prior we assume\n\\[\nd_{1k} \\sim \\mathcal{N}(0, 100^2)\n\\]\nMulti-arm trials\nSuppose each study \\(i\\) has \\(a_i+1\\) treatments (1 reference, e.g. control or placebo, and \\(a_i\\) treatments), so all effect measures of treatment in arm \\(k\\) compared with treatment in arm \\(1\\) are \\(\\boldsymbol{\\delta}_i = (\\delta_{i,12}, \\delta_{i,13}, \\dots, \\delta_{i,1a_i})^{\\top}\\) and\n\\[\n\\boldsymbol{\\delta}_i = (\\delta_{i,12}, \\delta_{i,13}, \\dots, \\delta_{i,1a_i})^{\\top} \\sim \\mathcal{N}_{a_i}\\begin{pmatrix}\n\\begin{pmatrix}\nd_{t_{i1},t_{i2}}\\\\\nd_{t_{i1},t_{i3}}\\\\\n\\vdots\\\\\nd_{t_{i1},t_{ia_i}}\n\\end{pmatrix},\n\\begin{pmatrix}\n\\sigma^2 & \\sigma^2/2 & \\dots & \\sigma^2/2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\sigma^2/2 & \\sigma^2/2 & \\dots & \\sigma^2\n\\end{pmatrix}\n\\end{pmatrix}\n\\] and we can show that\n\\[\n\\delta_{i,1k}|(\\delta_{i,12}, \\dots, \\delta_{i,1(k-1)})^{\\top} \\sim \\mathcal{N}\\Bigg(\n(d_{1,t_{ik}}-d_{1,t_{í}})+\\frac{1}{k-1}\\sum^{k-1}_{j=1}\\Big[\\delta_{i,1j}-\\big(d_{1,t_{ij}}-d_{1,t_{i1}}\\big)\\Big],\n\\frac{k}{2(k-1)}\\sigma^2\n\\Bigg)\n\\]\nExample\nFor illustration, we consider 36 studies including 7 treatments. We will\n\n\n\n",
      "last_modified": "2021-12-08T23:36:51-05:00"
    },
    {
      "path": "010301.html",
      "title": "Bayesian Sample Size Determination",
      "author": [
        {
          "name": "Nam Anh",
          "url": {}
        }
      ],
      "date": "Nov. 20, 2021",
      "contents": "\n\nContents\n1 Bayesian criteria for sample size\n2 Determine size size for normal distribution\n2.1 Single normal mean\n2.2 Difference between two normal mean (common precision)\n\n\n1 Bayesian criteria for sample size\nLet \\(\\boldsymbol{\\mathfrak{X}} \\ni \\boldsymbol{x} = (x_1,\\dots,x_n)^{\\top}\\) and \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) are a random sample with the size of \\(n\\) and parameter of interest, respectively. The predictive distribution of \\(\\{x_i\\}_{i=1}^n\\), i.e. pre-posterior distribution, is capable of obtaining from likelihood function as follows\n\\[\nf(x_i) = \\int_{\\boldsymbol{\\Theta}} f(x|\\boldsymbol{\\theta})d\\boldsymbol{\\theta},\n\\tag{1}\n\\] and the posterior distribution can be obtained\n\\[\nf(\\boldsymbol{\\theta}|x) = \\frac{f(x|\\boldsymbol{\\theta})f(\\boldsymbol{\\theta})}{f(x)},\n\\tag{2}\n\\]\n(2) also means\n\\[\nf(\\boldsymbol{\\theta}|x) \\propto f(x|\\boldsymbol{\\theta})f(\\boldsymbol{\\theta}).\n\\]\nThe posterior coverage probability of region R with volume of V is given by\n\\[\n\\int_{R}f(\\boldsymbol{\\theta}|x)d\\boldsymbol{\\theta},\n\\]\nR is HPD iff \\(f(\\boldsymbol{\\theta}_1|x) \\ge f(\\boldsymbol{\\theta}_2|x), \\forall \\boldsymbol{\\theta}_1 \\in R, \\boldsymbol{\\theta}_2 \\notin R\\). We now consider \\(\\boldsymbol{\\Theta}\\) is one-dimensional space, namely \\(\\boldsymbol{\\theta}\\) can be written as \\(\\theta\\). For the case of monotone increasing posterior densities defined on \\((u,v)\\), the corresponding condition for HPD is modified, see [1] for further detail.\nThree criteria considered in [1] are average coverage, average length and worst outcome, but we shall consider the average length criterion (ALC) in this review. Such a criterion is given by\n\\[\n\\int_{a(x,n)}^{a(x,n)+l'(x,n)}f(\\theta|x)d\\theta = 1-\\alpha,\n\\tag{3}\n\\]\nhere we fix the coverage probability \\(1-\\alpha\\) of HPD credible set for \\(\\theta\\). Each \\(x\\) will need a certain \\(l'(x,n)\\) to reach the desired coverage probability. We then calculate the expectation of \\(l'(x,n)\\) w.r.t predictive distribution \\(f(x)\\) and such a expectation is less than or equal a pre-specified length \\(l\\),\n\\[\n\\int_{\\mathfrak{X}}l'(x,n)f(x)dx \\le l,\n\\tag{4}\n\\]\n2 Determine size size for normal distribution\n2.1 Single normal mean\nSuppose we have a random vector \\(\\boldsymbol{X} = (X_1,X_2,\\dots,X_n)\\) that comprises exchangeable components following normal distribution with mean \\(\\mu\\) and precision \\(\\lambda = 1/\\sigma^2\\). prior distributions of \\(\\mu\\) and \\(\\lambda\\) are\n\\[\n\\lambda \\sim \\mathcal{Ga}(\\nu,\\beta),\n\\tag{5}\n\\]\nand\n\\[\n\\mu|\\lambda \\sim \\mathcal{N}(\\mu_0, n_0\\lambda)\n\\tag{6}\n\\]\nHere, we suppose both \\(\\mu\\) and \\(\\tau\\) are unknown, and marginal posterior distribution \\(\\mu|\\boldsymbol{x}\\) is\n\\[\n\\mu|\\boldsymbol{x} \\sim t_{2\\nu+n}\\sqrt{\\frac{\\beta_n}{(n+n_0)(\\nu+n/2)}}+\\mu_n,\n\\tag{7}\n\\]\nwhere\n\\[\n\\mu_n = \\frac{n_0\\mu_0+n\\overline{x}}{n+n_0}\n\\]\nand\n\\[\n\\beta_n = \\beta+ \\frac{1}{2}ns^2+\\frac{1}{2}\\frac{nn_0}{n+n_0}(\\overline{x}-\\mu_0)^2, \\text{ where } ns^2 = \\sum_{i=1}^n(x_i-\\overline{x})^2\n\\] SSD w.r.t ALC criterion is obtained in [2] as \\(n\\) is sufficiently large such that\n\\[\nl \\ge 2 t_{n+2\\nu, 1-\\alpha/2}\\sqrt{\\frac{2\\beta}{(n+2\\nu)(n+n_0)}}\\frac{\\Gamma(\\frac{n+2\\nu}{2})\\Gamma(\\frac{2\\nu-1}{2})}{\\Gamma(\\frac{n+2\\nu-1}{2})\\Gamma(\\nu)}\n\\tag{8}\n\\]\nWe shall now consider how to choose hyperparameters \\(\\nu\\) and \\(\\beta\\) for the precision \\(\\lambda\\). Suppose the aim is to obtain sample size of each treatment arm in a three-arm studies in which mean and standard deviation of outcome associated with each arm are known. This is,\n\n\nhide\n\nif(!library(pacman, logical.return = T)) install.packages(\"pacman\")\npacman::p_load(tidyverse, magrittr,HDInterval)\nd<-\ntibble(\n  Agent = c(\"midazolam\", \"lidocaine\", \"placebo\"),\n  Mean = c(3.2,4,4.8),\n  SE = c(2.9, 3.3,3.4),\n  n = c(57,52,50)\n)\nknitr::kable(d, caption = \"summary statistics obtained from other studies\")\n\n\nTable 1: summary statistics obtained from other studies\nAgent\nMean\nSE\nn\nmidazolam\n3.2\n2.9\n57\nlidocaine\n4.0\n3.3\n52\nplacebo\n4.8\n3.4\n50\n\nTo calculate sample size of midazolam we suppose data \\(X \\sim \\mathcal{N}(\\mu,\\tau)\\) where \\(\\tau\\) is precision, and\n\\[\n\\tau \\sim \\mathcal{Ga}(\\nu, \\beta),  \\text{ and} \\quad \\mu|\\tau \\sim \\mathcal{N}(\\mu_{MI}, n_{MI}\\tau),\n\\tag{9}\n\\]\nwhere \\(\\nu\\) and \\(\\beta\\) are obtained by solving the following equations\n\\[\n\\begin{cases}\n(\\nu-1)\\beta = \\tau_{MI} \\textit{ (mode of gamma distribution)}\\\\\n\\nu\\beta^2 = S^2_{\\tau_{MI}} \\textit{ (variance of gamma distribution)}\n\\end{cases}\n\\tag{10}\n\\]\nwhere\n\\[\n\\begin{align}\n&\\tau_{MI} =1/ n_{MI}SE^2_{MI},\\\\\n&S^2_{\\tau_{MI}} = \\frac{1}{2}\\big[(\\tau_{LI}-\\tau_{MI})^2+(\\tau_{PL}-\\tau_{MI})^2\\big].\n\\end{align}\n\\]\n\\(\\nu\\) and \\(\\beta\\) can be solved analytically. We then can solve (8) to obtain the sample size, or we can use (9) to simulate data \\(\\boldsymbol{x}\\) and calculate ALC. We shall now use information in Table 1 to obtain \\(\\nu\\) and \\(\\beta\\). To this end, we calculate SD for each treatment\n\n\nhide\n\nd%<>%\n  mutate(SD = SE*sqrt(n), .before = \"n\")%>%\n  mutate(SD = `names<-`(SD,Agent), `$$\\\\tau$$` = 1/SD^2)\nkableExtra::kbl(d, caption = \"SD of treatments\")%>%\n  kableExtra::kable_styling()\n\n\n\nTable 2: SD of treatments\n\n\nAgent\n\n\nMean\n\n\nSE\n\n\nSD\n\n\nn\n\n\n\\[\\tau\\]\n\n\nmidazolam\n\n\n3.2\n\n\n2.9\n\n\n21.89452\n\n\n57\n\n\n0.0020861\n\n\nlidocaine\n\n\n4.0\n\n\n3.3\n\n\n23.79664\n\n\n52\n\n\n0.0017659\n\n\nplacebo\n\n\n4.8\n\n\n3.4\n\n\n24.04163\n\n\n50\n\n\n0.0017301\n\n\nSolving (10) we have\n\\[\n\\beta = \\frac{-\\tau + \\sqrt{\\tau^2+4S^2_{\\tau}}}{2},\n\\]\nsince product \\(\\beta_1\\beta_2 < 0\\), \\(\\beta_1\\) and \\(\\beta_2\\) must have opposite signs. It means one of two roots must be a positive number.\nWe shall obtain \\(\\beta\\) and plot density function of \\(\\tau\\) with parameters \\(\\nu\\) and \\(\\beta\\).\n\n\nhide\n\ntau = 1/d$SD[1]^2\ns2 = mean((1/d$SD[2:3]^2-tau)^2)\nbeta = (-tau+sqrt(tau^2+4*s2))/2\nnu = tau/beta+1\nx = rgamma(5000, shape = nu, scale = beta)%>% sort()\nplot(x,dgamma(x,shape = nu, scale = beta),\n     xlab = \"\",\n     col = \"gray40\", main = \"\", type = \"l\")\nabline(v = (nu-1)*beta, col = \"gray40\")\nabline(v =1/d$SD^2, col = \"red\", lty = 2)\n\n\n\n\nFigure 1: Density of Gamma distribution\n\n\n\nNext, We use (8) to obtain values of \\(l\\) w.r.t to fixed values of \\(n\\)\n\n\nhide\n\nn = seq(200,300, by = 10)\nl<-\n  sapply(n, function(i){\n    p = lgamma((i+2*nu)/2)+ lgamma((2*nu-1)/2)-lgamma((i+2*nu-1)/2)-lgamma(nu)\n    2*qt(0.975,i+2*nu)*sqrt(2*beta/(i+2*nu)/(i+d$n[1]))*exp(p)\n})\n\ntibble(\"Sample size\" = n, \"ALC\" = l)%>%\n  knitr::kable(caption = \"sample size and average length criterion (analytical)\")%>%\n  kableExtra::kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\"),\n    full_width = TRUE)%>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\",\n                         box_css = \"align: center; \",\n                         extra_css = \"border: none; left: 200px; \"\n                         )\n\n\n\n\nTable 3: sample size and average length criterion (analytical)\n\n\nSample size\n\n\nALC\n\n\n200\n\n\n0.0002863\n\n\n210\n\n\n0.0002809\n\n\n220\n\n\n0.0002758\n\n\n230\n\n\n0.0002709\n\n\n240\n\n\n0.0002663\n\n\n250\n\n\n0.0002619\n\n\n260\n\n\n0.0002577\n\n\n270\n\n\n0.0002537\n\n\n280\n\n\n0.0002499\n\n\n290\n\n\n0.0002463\n\n\n300\n\n\n0.0002428\n\n\n\n2.2 Difference between two normal mean (common precision)\nSuppose we have data \\(\\boldsymbol{x}_{12}^{\\top} = (\\boldsymbol{x}_1^{\\top},\\boldsymbol{x}_2^{\\top})\\), where \\(\\boldsymbol{x}_1 = (x_{11}, x_{21},\\dots,x_{n_11})^{\\top}\\), \\(\\boldsymbol{x}_2 = (x_{12}, x_{22},\\dots,x_{n_22})^{\\top}\\) and \\(x_{ij} \\sim \\mathcal{N}(\\mu_j,\\lambda)\\) with \\(i = 1,2,\\dots,n_j\\), \\(j = 1,2\\), note that \\(\\lambda\\) is precision. Again we suppose\n\\[\n\\lambda \\sim \\mathcal{Ga}(\\nu,\\beta), \\text{ and} \\quad \\mu_j|\\lambda \\sim \\mathcal{N}(\\mu_{0j}, n_{0j}\\lambda)\n\\tag{11}\n\\]\nParameter of interest is \\(\\theta = \\mu_1-\\mu_2\\) and\n\\[\n\\theta|\\boldsymbol{x}_{12} \\sim A + \\sqrt{\\frac{B}{2CD}}t_{2C}\n\\tag{12}\n\\]\nwhere\n\\[\n\\begin{align}\n&A = \\frac{n_2\\overline{x}_2+n_{02}\\mu_{02}}{n_2+n_{02}}\\\\\n&B = 2\\beta+n_1s^2_1+n_2s^2_2+\\frac{n_1n_{01}}{n_1+n_{01}}(\\overline{x}_1-\\mu_{01})^2+\\frac{n_2n_{02}}{n_2+n_{02}}(\\overline{x}_2-\\mu_{02})^2\\\\\n&C = \\frac{n_1+n_2}{2}+\\nu\\\\\n&D = \\frac{(n_1+n_{01})(n_2+n_{02})}{n_1+n_{01}+n_2+n_{02}}\n\\end{align}\n\\tag{13}\n\\]\nThus, \\(n_1\\) and \\(n_2\\) can be obtained by solving following equations\n\\[\n\\begin{cases}\nn_1+n_{01} = n_2+n_{02},\\quad\\textit{(minimize expected variance posterior)}\\\\\n2t_{n_1+n_2+2\\nu;1-\\alpha/2}\\sqrt{\\frac{2\\beta(n_1+n_{01}+n_2+n_{02})}{(n_1+n_2+2\\nu)(n_1+n_{01})(n_2+n_{02})}}\\frac{\\Gamma\\big(\\frac{n_1+n_2+2\\nu}{2}\\big)\\Gamma\\big(\\frac{2\\nu-1}{2}\\big)}{\\Gamma\\big(\\frac{n_1+n_2+2\\nu-1}{2}\\big)\\Gamma\\big(\\nu\\big)} \\le l\n\\end{cases}\n\\tag{14}\n\\]\n\\(\\nu\\) and \\(\\beta\\) are obtained in a similar way to that in previous section. For example, we want to obtain \\(n_1\\) and \\(n2\\) that are sample size of midazolam and placebo, respectively. Thus \\(\\nu\\) and \\(\\beta\\) are roots of following equations\n\\[\n\\begin{cases}\n(\\nu-1)\\beta = \\frac{1}{3}(\\tau_{01}+\\tau_{02}+\\tau_{03}),\\quad\\textit{(mode)}\\\\\n\\nu\\beta^2 = \\frac{1}{2}\\sum_{i=1}^3(\\tau_{0i}-\\overline{\\tau}_0)^2,\\quad\\textit{(variance)}\n\\end{cases}\n\\]\n\n\nhide\n\ns2 = var(pull(d,6))\ntau0 = mean(pull(d,6))\nbeta = (-tau0+sqrt(tau0^2+4*s2))/2\nnu = tau0/beta+1\n\nx = rgamma(1000, shape = nu, scale = beta)%>% sort()\nplot(x,dgamma(x,shape = nu, scale = beta), main = \"\", xlab = \"\", type = \"l\")\nabline(v =tau0)\nabline(v = pull(d,6), col = \"red\", lty = 2)\n\n\n\n\nFigure 2: Density of Gamma distribution\n\n\n\nWe now write \\(n_2\\) in term of \\(n_1\\) in first equation of (14), i.e. \\(n_2 = n_1+n_{01}-n_{02}\\). Next we plug this equation to second equation of (14) and solve the equation.\n\n\nhide\n\nn01 = d$n[1]; n02 = d$n[3] \n\nfunc = function(n){\n  \n  2*qt(0.975,n+n+n01-n02+2*nu)*sqrt(4*beta*(n+n01)/(2*n+n01-n02+2*nu)/(n+n01)/(n+n01))*exp(\n    lgamma((2*n+n01-n02+2*nu)/2)+\n    lgamma((2*nu-1)/2)-\n    lgamma((2*n+n01-n02+2*nu-1)/2)-\n    lgamma(nu)\n  )\n}\nfunc = Vectorize(func)\n\nn = seq(100,500, by = 10)\n\nn1n2<-\ntibble(n1 = n)%>%\n  mutate(ALC = func(n))%>%\n  mutate(n2 = n1+n01-n02, .before = \"ALC\")\n\nn1n2%>%\n  kableExtra::kbl(caption = \"Sample size of midazolam, placebo.\")%>%\n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\"), full_width = TRUE)%>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\",\n                         box_css = \"align: center; \",\n                         extra_css = \"border: none; left: 200px; \"\n                         )\n\n\n\n\nTable 4: Sample size of midazolam, placebo.\n\n\nn1\n\n\nn2\n\n\nALC\n\n\n100\n\n\n107\n\n\n0.0002094\n\n\n110\n\n\n117\n\n\n0.0002030\n\n\n120\n\n\n127\n\n\n0.0001972\n\n\n130\n\n\n137\n\n\n0.0001919\n\n\n140\n\n\n147\n\n\n0.0001869\n\n\n150\n\n\n157\n\n\n0.0001823\n\n\n160\n\n\n167\n\n\n0.0001781\n\n\n170\n\n\n177\n\n\n0.0001741\n\n\n180\n\n\n187\n\n\n0.0001704\n\n\n190\n\n\n197\n\n\n0.0001669\n\n\n200\n\n\n207\n\n\n0.0001636\n\n\n210\n\n\n217\n\n\n0.0001605\n\n\n220\n\n\n227\n\n\n0.0001576\n\n\n230\n\n\n237\n\n\n0.0001548\n\n\n240\n\n\n247\n\n\n0.0001522\n\n\n250\n\n\n257\n\n\n0.0001497\n\n\n260\n\n\n267\n\n\n0.0001473\n\n\n270\n\n\n277\n\n\n0.0001450\n\n\n280\n\n\n287\n\n\n0.0001429\n\n\n290\n\n\n297\n\n\n0.0001408\n\n\n300\n\n\n307\n\n\n0.0001388\n\n\n310\n\n\n317\n\n\n0.0001369\n\n\n320\n\n\n327\n\n\n0.0001351\n\n\n330\n\n\n337\n\n\n0.0001333\n\n\n340\n\n\n347\n\n\n0.0001316\n\n\n350\n\n\n357\n\n\n0.0001300\n\n\n360\n\n\n367\n\n\n0.0001284\n\n\n370\n\n\n377\n\n\n0.0001269\n\n\n380\n\n\n387\n\n\n0.0001254\n\n\n390\n\n\n397\n\n\n0.0001240\n\n\n400\n\n\n407\n\n\n0.0001227\n\n\n410\n\n\n417\n\n\n0.0001213\n\n\n420\n\n\n427\n\n\n0.0001201\n\n\n430\n\n\n437\n\n\n0.0001188\n\n\n440\n\n\n447\n\n\n0.0001176\n\n\n450\n\n\n457\n\n\n0.0001164\n\n\n460\n\n\n467\n\n\n0.0001153\n\n\n470\n\n\n477\n\n\n0.0001142\n\n\n480\n\n\n487\n\n\n0.0001131\n\n\n490\n\n\n497\n\n\n0.0001121\n\n\n500\n\n\n507\n\n\n0.0001111\n\n\n\nAgain, we use second equation in (14) to calculate \\(n_3\\), i.e. we plug all values of \\(n_2\\) in the equation and search for \\(n_3\\). Suppose we choose \\(n1\\) and \\(n_2\\) are 130 and 137, respectively.\n\n\nhide\n\nn2 = pull(n1n2[4,2])\nn03 = d$n[2]\n\nfunc2 = function(n1){\n  p = lgamma((n1+n2+2*nu)/2)+lgamma((2*nu-1)/2)-lgamma((n1+n2+2*nu-1)/2)-lgamma(nu)\n  2*qt(0.975,n1+n2+2*nu)*sqrt(2*beta*(n1+n01+n2+n02)/(n1+n2+2*nu)/(n1+n01)/(n2+n02))*exp(p)\n}\n\nn2n3<-\nmap2_dfr(n1n2$n1,n1n2$n2,~{\n  tibble(n1 = .x, n2 = .y, n3 = c(.x,.x+3,.y))%>%\n  mutate(ALC = func2(n3))\n})%>%\n  arrange(desc(ALC))\n\nn2n3%>%\n  kableExtra::kbl(caption =  paste0(\"Sample size of lidocaine when sample size of placebo is \",n2,\".\"))%>%\n  kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\"), full_width = TRUE)%>%\n  kableExtra::scroll_box(width = \"100%\", height = \"400px\",\n                         box_css = \"align: center; \",\n                         extra_css = \"border: none; left: 200px; \"\n                         )\n\n\n\n\nTable 5: Sample size of lidocaine when sample size of placebo is 137.\n\n\nn1\n\n\nn2\n\n\nn3\n\n\nALC\n\n\n100\n\n\n107\n\n\n100\n\n\n0.0002008\n\n\n100\n\n\n107\n\n\n103\n\n\n0.0001998\n\n\n100\n\n\n107\n\n\n107\n\n\n0.0001985\n\n\n110\n\n\n117\n\n\n110\n\n\n0.0001975\n\n\n110\n\n\n117\n\n\n113\n\n\n0.0001966\n\n\n110\n\n\n117\n\n\n117\n\n\n0.0001954\n\n\n120\n\n\n127\n\n\n120\n\n\n0.0001946\n\n\n120\n\n\n127\n\n\n123\n\n\n0.0001937\n\n\n120\n\n\n127\n\n\n127\n\n\n0.0001926\n\n\n130\n\n\n137\n\n\n130\n\n\n0.0001919\n\n\n130\n\n\n137\n\n\n133\n\n\n0.0001911\n\n\n130\n\n\n137\n\n\n137\n\n\n0.0001901\n\n\n140\n\n\n147\n\n\n140\n\n\n0.0001894\n\n\n140\n\n\n147\n\n\n143\n\n\n0.0001887\n\n\n140\n\n\n147\n\n\n147\n\n\n0.0001878\n\n\n150\n\n\n157\n\n\n150\n\n\n0.0001872\n\n\n150\n\n\n157\n\n\n153\n\n\n0.0001865\n\n\n150\n\n\n157\n\n\n157\n\n\n0.0001857\n\n\n160\n\n\n167\n\n\n160\n\n\n0.0001851\n\n\n160\n\n\n167\n\n\n163\n\n\n0.0001845\n\n\n160\n\n\n167\n\n\n167\n\n\n0.0001838\n\n\n170\n\n\n177\n\n\n170\n\n\n0.0001832\n\n\n170\n\n\n177\n\n\n173\n\n\n0.0001827\n\n\n170\n\n\n177\n\n\n177\n\n\n0.0001820\n\n\n180\n\n\n187\n\n\n180\n\n\n0.0001814\n\n\n180\n\n\n187\n\n\n183\n\n\n0.0001809\n\n\n180\n\n\n187\n\n\n187\n\n\n0.0001803\n\n\n190\n\n\n197\n\n\n190\n\n\n0.0001798\n\n\n190\n\n\n197\n\n\n193\n\n\n0.0001793\n\n\n190\n\n\n197\n\n\n197\n\n\n0.0001787\n\n\n200\n\n\n207\n\n\n200\n\n\n0.0001783\n\n\n200\n\n\n207\n\n\n203\n\n\n0.0001779\n\n\n200\n\n\n207\n\n\n207\n\n\n0.0001773\n\n\n210\n\n\n217\n\n\n210\n\n\n0.0001769\n\n\n210\n\n\n217\n\n\n213\n\n\n0.0001765\n\n\n210\n\n\n217\n\n\n217\n\n\n0.0001759\n\n\n220\n\n\n227\n\n\n220\n\n\n0.0001756\n\n\n220\n\n\n227\n\n\n223\n\n\n0.0001752\n\n\n220\n\n\n227\n\n\n227\n\n\n0.0001747\n\n\n230\n\n\n237\n\n\n230\n\n\n0.0001743\n\n\n230\n\n\n237\n\n\n233\n\n\n0.0001740\n\n\n230\n\n\n237\n\n\n237\n\n\n0.0001735\n\n\n240\n\n\n247\n\n\n240\n\n\n0.0001732\n\n\n240\n\n\n247\n\n\n243\n\n\n0.0001728\n\n\n240\n\n\n247\n\n\n247\n\n\n0.0001724\n\n\n250\n\n\n257\n\n\n250\n\n\n0.0001721\n\n\n250\n\n\n257\n\n\n253\n\n\n0.0001717\n\n\n250\n\n\n257\n\n\n257\n\n\n0.0001713\n\n\n260\n\n\n267\n\n\n260\n\n\n0.0001710\n\n\n260\n\n\n267\n\n\n263\n\n\n0.0001707\n\n\n260\n\n\n267\n\n\n267\n\n\n0.0001703\n\n\n270\n\n\n277\n\n\n270\n\n\n0.0001700\n\n\n270\n\n\n277\n\n\n273\n\n\n0.0001698\n\n\n270\n\n\n277\n\n\n277\n\n\n0.0001694\n\n\n280\n\n\n287\n\n\n280\n\n\n0.0001691\n\n\n280\n\n\n287\n\n\n283\n\n\n0.0001689\n\n\n280\n\n\n287\n\n\n287\n\n\n0.0001685\n\n\n290\n\n\n297\n\n\n290\n\n\n0.0001683\n\n\n290\n\n\n297\n\n\n293\n\n\n0.0001680\n\n\n290\n\n\n297\n\n\n297\n\n\n0.0001677\n\n\n300\n\n\n307\n\n\n300\n\n\n0.0001674\n\n\n300\n\n\n307\n\n\n303\n\n\n0.0001672\n\n\n300\n\n\n307\n\n\n307\n\n\n0.0001669\n\n\n310\n\n\n317\n\n\n310\n\n\n0.0001666\n\n\n310\n\n\n317\n\n\n313\n\n\n0.0001664\n\n\n310\n\n\n317\n\n\n317\n\n\n0.0001661\n\n\n320\n\n\n327\n\n\n320\n\n\n0.0001659\n\n\n320\n\n\n327\n\n\n323\n\n\n0.0001657\n\n\n320\n\n\n327\n\n\n327\n\n\n0.0001654\n\n\n330\n\n\n337\n\n\n330\n\n\n0.0001652\n\n\n330\n\n\n337\n\n\n333\n\n\n0.0001650\n\n\n330\n\n\n337\n\n\n337\n\n\n0.0001647\n\n\n340\n\n\n347\n\n\n340\n\n\n0.0001645\n\n\n340\n\n\n347\n\n\n343\n\n\n0.0001643\n\n\n340\n\n\n347\n\n\n347\n\n\n0.0001640\n\n\n350\n\n\n357\n\n\n350\n\n\n0.0001638\n\n\n350\n\n\n357\n\n\n353\n\n\n0.0001636\n\n\n350\n\n\n357\n\n\n357\n\n\n0.0001634\n\n\n360\n\n\n367\n\n\n360\n\n\n0.0001632\n\n\n360\n\n\n367\n\n\n363\n\n\n0.0001630\n\n\n360\n\n\n367\n\n\n367\n\n\n0.0001628\n\n\n370\n\n\n377\n\n\n370\n\n\n0.0001626\n\n\n370\n\n\n377\n\n\n373\n\n\n0.0001625\n\n\n370\n\n\n377\n\n\n377\n\n\n0.0001622\n\n\n380\n\n\n387\n\n\n380\n\n\n0.0001621\n\n\n380\n\n\n387\n\n\n383\n\n\n0.0001619\n\n\n380\n\n\n387\n\n\n387\n\n\n0.0001617\n\n\n390\n\n\n397\n\n\n390\n\n\n0.0001615\n\n\n390\n\n\n397\n\n\n393\n\n\n0.0001613\n\n\n390\n\n\n397\n\n\n397\n\n\n0.0001611\n\n\n400\n\n\n407\n\n\n400\n\n\n0.0001610\n\n\n400\n\n\n407\n\n\n403\n\n\n0.0001608\n\n\n400\n\n\n407\n\n\n407\n\n\n0.0001606\n\n\n410\n\n\n417\n\n\n410\n\n\n0.0001605\n\n\n410\n\n\n417\n\n\n413\n\n\n0.0001603\n\n\n410\n\n\n417\n\n\n417\n\n\n0.0001601\n\n\n420\n\n\n427\n\n\n420\n\n\n0.0001600\n\n\n420\n\n\n427\n\n\n423\n\n\n0.0001599\n\n\n420\n\n\n427\n\n\n427\n\n\n0.0001597\n\n\n430\n\n\n437\n\n\n430\n\n\n0.0001595\n\n\n430\n\n\n437\n\n\n433\n\n\n0.0001594\n\n\n430\n\n\n437\n\n\n437\n\n\n0.0001592\n\n\n440\n\n\n447\n\n\n440\n\n\n0.0001591\n\n\n440\n\n\n447\n\n\n443\n\n\n0.0001590\n\n\n440\n\n\n447\n\n\n447\n\n\n0.0001588\n\n\n450\n\n\n457\n\n\n450\n\n\n0.0001587\n\n\n450\n\n\n457\n\n\n453\n\n\n0.0001585\n\n\n450\n\n\n457\n\n\n457\n\n\n0.0001584\n\n\n460\n\n\n467\n\n\n460\n\n\n0.0001582\n\n\n460\n\n\n467\n\n\n463\n\n\n0.0001581\n\n\n460\n\n\n467\n\n\n467\n\n\n0.0001580\n\n\n470\n\n\n477\n\n\n470\n\n\n0.0001578\n\n\n470\n\n\n477\n\n\n473\n\n\n0.0001577\n\n\n470\n\n\n477\n\n\n477\n\n\n0.0001576\n\n\n480\n\n\n487\n\n\n480\n\n\n0.0001575\n\n\n480\n\n\n487\n\n\n483\n\n\n0.0001573\n\n\n480\n\n\n487\n\n\n487\n\n\n0.0001572\n\n\n490\n\n\n497\n\n\n490\n\n\n0.0001571\n\n\n490\n\n\n497\n\n\n493\n\n\n0.0001570\n\n\n490\n\n\n497\n\n\n497\n\n\n0.0001568\n\n\n500\n\n\n507\n\n\n500\n\n\n0.0001567\n\n\n500\n\n\n507\n\n\n503\n\n\n0.0001566\n\n\n500\n\n\n507\n\n\n507\n\n\n0.0001565\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[1] Joseph L, Wolfson DB, Berger RD. Sample size calculations for binomial proportions via highest posterior density intervals. The Statistician 1995;44:143.\n\n\n[2] Joseph L, Bélisle P. Bayesian sample size determination for normal means and differences between normal means. Journal of the Royal Statistical Society Series D (The Statistician) 1997;46:209–26.\n\n\n\n\n",
      "last_modified": "2021-12-08T23:37:07-05:00"
    },
    {
      "path": "index.html",
      "title": "Bayesian Statistics",
      "description": "\"Begin with an estimate of the probability that any claim, belief, hypothesis is true, then look at any new data and update the probability given the new data.\"\n\n-Steven Novella-\n",
      "author": [],
      "contents": "\n\n\n\n",
      "last_modified": "2021-12-08T23:37:09-05:00"
    }
  ],
  "collections": []
}
