---
title: "Bayesian Computational Approaches"
subtitle: "010101"
description: |
author:
  - name: Nam Anh
date: "Oct. 11, 2021"
bibliography: citation.bib
output:
  distill::distill_article:
    toc: true
    toc_depth: 3
---

\newcommand{\v}[1]{\boldsymbol{#1}}
\newcommand{\hat}[1]{\widehat{#1}}
\newcommand{\mm}[1]{\mathbb{#1}}
\newcommand{\bar}[1]{\overline{#1}}

\def\E{\Bbb{E}}
\def\V{\Bbb{V}}
\def\P{\Bbb{P}}
\def\I{{\large\unicode{x1D7D9}}}
\def\indep{\perp\!\!\!\!\perp}
\newcommand{\overeq}[2]{\stackrel{#1}{#2}}
\def\epsilon{\varepsilon} 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


# Maximize posterior distribution

Let us define $p(\v{\theta}|\v{Y})$ be posterior distribution, and 

$$
\hat{\v{\theta}}_{MAP} = \arg\max_{\v\theta}\ln p(\v{\theta}|\v{Y}) = \arg\max_{\v\theta}\ln f(\v{Y}|\v{\theta}) + \ln \pi(\v\theta)
(\#eq:1)
$$
is the maximizer of $p(\v{\theta}|\v{Y})$. 

MAP estimator can be obtained by function `optim` in `R`. Its illustration in R will be pored over latter. 

# Numerical integration

Some summary statistics of interest can be written as integrals, so they can be approximated by summations. For example, expectation, variance and proportions of a distribution can be written as follows

$$
\begin{aligned}
\E(\theta|\v{Y}) &= \int \theta_1p(\theta|\v{Y})d\theta \\
\V(\theta|\v{Y}) &= \int [\theta - \E(\theta|\v{Y})]^2p(\theta|\v{Y})d\theta \\
\P(\theta > c|\v Y) &= \int_c^{\infty}p(\theta|\v{Y})d\theta
\end{aligned}(\#eq:2)
$$